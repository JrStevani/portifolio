<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projetos</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #2c2c2c;
            color: #ffffff;
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }

        ::-webkit-scrollbar {
            display: none; /* Oculta a barra de rolagem */
        }


        header {
            background-color: #1c1c1c;
            padding: 15px;
            text-align: center;
        }

        header h1 {
            margin: 0;
            font-size: 2.5em;
        }

        .container {
            display: flex;
            flex: 1;
            flex-direction: row;
        }

        nav {
            background-color: #333333;
            padding: 20px;
            width: 250px;
            box-sizing: border-box;
            display: flex;
            flex-direction: column;
            align-items: center;
            height: 90vh;
        }

        nav img {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            margin-bottom: 20px;
            border: 3px solid #ffffff;
        }

        a {
            color: black;
            text-decoration: none;
            margin: 10px 0;
            font-size: 1.2em;
            text-align: center;
            width: 100%;
            padding: 10px;
            box-sizing: border-box;
            border-radius: 8px;
            border: 1px solid black;
        }

        a:hover {
            background-color: #f5f5f5;
        }

        section {
            display: block;
            padding: 20px;
            flex: 1;
            max-width: 100%;
            box-sizing: border-box;
        }

        .project {
            background-color: rgb(247, 247, 247);
            color: black;
            padding: 15px;
            margin-bottom: 20px;
            border-radius: 8px;
        }

        .project h2 {
            margin-top: 0;
            color: #181a20;
        }

        footer {
            background-color: #1c1c1c;
            padding: 1px;
            text-align: center;
            color: #777777;
        }

        @media (max-width: 768px) {
            .container {
                flex-direction: column;
            }

            nav {
                width: 100%;
                flex-direction: row;
                justify-content: space-around;
            }

            nav img {
                display: none;
            }

            nav a {
                margin: 5px;
                padding: 10px;
                font-size: 1em;
            }
        }
    </style>
</head>
<body>
    <main>
        <section>
            <div id="web-scraping" class="project">
                <h2>Web Scraping em site de anime</h2>
                
        
                <a href="https://jrstevani.github.io/Web-Scraping-em-site-de-anime/index.html" target="_blank"><strong>Projeto detalhado</strong></a>
        
                <p><strong>Descrição do Projeto:</strong></p>
        
                <p><strong>Web Scraping de Animes:</strong> Captura de IDs de Episódios e Metadados</p>
        
                <p>Este projeto tem como objetivo realizar web scraping em um site de animes para capturar os IDs dos episódios de todos os animes hospedados no site. Utilizando a biblioteca Playwright, o projeto automatiza a navegação no site para extrair informações detalhadas sobre cada anime, incluindo:</p>
        
                <p><strong>Nome do Anime:</strong> Capturado e normalizado (sem acentuação).</p>
                <p><strong>Descrição:</strong> Texto descritivo do anime.</p>
                <p><strong>Gêneros:</strong> Lista de gêneros associados ao anime.</p>
                <p><strong>Imagem:</strong> URL da imagem de capa do anime.</p>
                <p><strong>Temporadas e Episódios:</strong> Lista de temporadas e URLs de cada episódio.</p>
                <P>As informações coletadas são organizadas e armazenadas em arquivos JSON, facilitando o acesso e manipulação dos dados. Além disso, o projeto mantém um registro de progresso e de erros em arquivos de texto, garantindo que o processo de scraping seja monitorado e que possíveis problemas sejam documentados.</p>
        
                <p><strong>Funcionalidades Principais:</strong></p>
        
                <p><strong>Criação de Pastas e Arquivos:</strong></p>
        
                <p>Cria diretórios específicos para armazenar os resultados de cada gênero (dublado e legendado).</p>
                <p>Gera arquivos JSON contendo os metadados dos animes e seus episódios.</p>
                <p><strong>Registro de Progresso e Erros:</strong></p>
        
                <p>Mantém um log do progresso em arquivos de texto.</p>
                <P>Documenta erros ocorridos durante a execução, facilitando a depuração.</p>
                <p><strong>Leitura de Dados Existentes:</strong></p>
        
                <p>Lê URLs de animes a partir de arquivos JSON existentes.</p>
                <p>Verifica se um anime já foi processado para evitar duplicidade.</p>
                <p><strong>Automação de Navegação:</strong></p>
        
                <p>Utiliza Playwright para navegar pelas páginas dos animes e extrair as informações desejadas.</p>
                <p>Processa os dados coletados e os salva em arquivos estruturados.</p>
                <p>Este projeto é ideal para aqueles que precisam extrair e organizar grandes volumes de dados de sites de forma eficiente e estruturada, oferecendo uma solução robusta para a captura e armazenamento de informações detalhadas sobre animes.</p>
            </div>
        
            <div id="data-analysis" class="project">
                <h1>PMPF Simplify</h1>
                <p><a href="https://jrstevani.github.io/PMPF-Simplify/" target="_blank"><strong>Projeto detalhado</strong></a></p>
                
                <h2>Descrição do Projeto e Funcionalidades</h2>
                <p>Este projeto tem como objetivo principal a padronização e análise de dados de produtos presentes em notas fiscais eletrônicas (NFes). Ele é dividido em duas etapas principais: a padronização de dados e a identificação de erros, seguida pela análise estatística e cálculo de variações. As funcionalidades do projeto incluem:</p>
                <ul>
                    <li><strong>Carregamento e validação de dados</strong>: Leitura de arquivos Excel contendo dados de produtos e tabela de erros.</li>
                    <li><strong>Padronização de dados</strong>: Aplicação de intervalos de aceitação para valores unitários e filtragem de valores discrepantes.</li>
                    <li><strong>Análise estatística</strong>: Cálculo de variâncias, desvios padrão e outras métricas estatísticas para cada grupo de produtos.</li>
                    <li><strong>Geração de relatórios</strong>: Criação de relatórios detalhados com análise de erros, variações de preços e distribuição de vendas por setor.</li>
                    <li><strong>Salvamento de resultados</strong>: Armazenamento dos dados padronizados e analisados em arquivos Excel para posterior revisão e utilização.</li>
                </ul>
                
                <h2>Detalhamento das Etapas</h2>
                
                <h3>Primeira Etapa: Padronização de Dados e Identificação de Erros</h3>
                <ul>
                    <li><strong>Carregamento de Dados</strong>: Carregamento de arquivos Excel contendo dados padronizados e tabela de erros. Verificação e carregamento de arquivo de configuração <code>Gtin.xlsx</code>.</li>
                    <li><strong>Inicialização de Estruturas</strong>: Criação de DataFrames para armazenar resultados, dados de desvio padrão, fornecedores e resultados finais. Inicialização de dicionários para armazenar variações e intervalos de aceitação.</li>
                    <li><strong>Cálculo de Intervalos de Aceitação</strong>: Cálculo de limites inferior e superior de aceitação para valores unitários de produtos agrupados por código GTIN.</li>
                    <li><strong>Filtragem de Dados</strong>: Filtragem de dados com base nos intervalos de aceitação. Valores dentro dos intervalos são considerados corretos, enquanto valores fora são classificados como erros.</li>
                    <li><strong>Análise Estatística</strong>: Cálculo de variâncias e desvios padrão para cada grupo de produtos. Cálculo do valor total das notas fiscais para posterior análise percentual.</li>
                    <li><strong>Compilação dos Resultados</strong>: Cálculo de várias métricas para cada produto e armazenamento em tabelas de resultados e fornecedores.</li>
                    <li><strong>Salvamento dos Resultados</strong>: Salvamento de DataFrames resultantes em um arquivo Excel, organizados em várias abas, incluindo dados padronizados, tabela de erros, dados tratados, relatório e análise de erros por fornecedores.</li>
                </ul>
                
                <h3>Segunda Etapa: Análise Estatística e Cálculo de Variações</h3>
                <ul>
                    <li><strong>Preparação dos Dados</strong>: Carregamento dos dados previamente padronizados e filtrados. Inicialização de estruturas de dados para armazenar resultados da análise estatística.</li>
                    <li><strong>Cálculo de Variações</strong>: Agrupamento de dados por código GTIN e cálculo de soma de unidades comerciais e valor total do produto. Cálculo de variâncias e desvios padrão para cada grupo de produtos.</li>
                    <li><strong>Análise de Desvios Padrão</strong>: Identificação de produtos com variações fora dos intervalos de aceitação. Remoção de valores discrepantes e recalculação de métricas.</li>
                    <li><strong>Compilação de Relatórios</strong>: Criação de relatórios detalhados contendo análise de quantidade de erros, variações de preços e distribuições de vendas por setor. Preenchimento de tabelas com dados consolidados e estatísticas calculadas.</li>
                    <li><strong>Salvamento Final dos Resultados</strong>: Salvamento de todos os resultados e análises em um arquivo Excel, organizados em abas específicas para fácil acesso e revisão.</li>
                </ul>
                
                <h2>Tecnologias Utilizadas</h2>
                <ul>
                    <li><strong>Python</strong>: Linguagem principal de programação utilizada para todo o desenvolvimento do projeto.</li>
                    <li><strong>Pandas</strong>: Biblioteca essencial para manipulação e análise de dados, usada para operações com DataFrames.</li>
                    <li><strong>Openpyxl</strong>: Biblioteca usada para leitura e escrita de arquivos Excel.</li>
                    <li><strong>NumPy</strong>: Biblioteca usada para cálculos numéricos e operações matemáticas.</li>
                    <li><strong>PyQt5</strong>: Biblioteca usada para criar a interface gráfica do usuário (GUI) que facilita a interação com o sistema.</li>
                    <li><strong>Os</strong>: Módulo usado para operações relacionadas ao sistema operacional, como verificação da existência de arquivos.</li>
                    <li><strong>Bibliotecas de estatística</strong>: Ferramentas para cálculos estatísticos como variância e desvio padrão.</li>
                </ul>
            </div>

            <div id="web-scraping-medicamentos" class="project">
                <h1>Web Scraping para Medicamentos</h1>
                <p><a href="https://jrstevani.github.io/Web_Scraping_Para_Medicamentos/" target="_blank"><strong>Projeto detalhado</strong></a></p>
                <h2>Descrição do Projeto e Funcionalidades</h2>
                <p>Este projeto visa capturar e analisar dados de medicamentos a partir dos sites "Consulta Remédios" e "Farmaindex" utilizando Python. Através de uma combinação de web scraping com as bibliotecas <code>BeautifulSoup</code> e requisições HTTP com a biblioteca <code>requests</code>, os scripts buscam informações planejadas sobre medicamentos com base em seus códigos EAN presentes em um arquivo Excel.</p>

                <h2>Funcionalidades do Projeto:</h2>
                <ul>
                    <li><strong>Leitura de Dados:</strong> Os scripts lêem os códigos EAN de medicamentos de uma planilha em um arquivo Excel.</li>
                    <li><strong>Web Scraping:</strong> Utilize a biblioteca <code>BeautifulSoup</code> para extrair dados específicos dos sites "Consulta Remédios" e "Farmaindex" como apresentação, nome do medicamento, princípio ativo e fabricante.</li>
                    <li><strong>Tratamento de Dados:</strong> Os dados extraídos são organizados em um DataFrame do Pandas para fácil manipulação e análise.</li>
                    <li><strong>Exportação de Dados:</strong> Os resultados são salvos em novas planilhas Excel, permitindo uma análise estruturada e comparativa dos dados.</li>
                </ul>

                <h2>Etapas do Processo:</h2>
                <ul>
                    <li><strong>Requisição HTTP:</strong> Realiza uma solicitação GET para a URL do medicamento com base no código EAN.</li>
                    <li><strong>Análise HTML:</strong> Utilize <code>BeautifulSoup</code> para analisar o conteúdo HTML e encontrar as divs específicas que contêm os dados necessários.</li>
                    <li><strong>Extração de Dados:</strong> Decodifica o JSON contido nos atributos HTML (no caso do "Consulta Remédios") ou extrai diretamente os textos das tags HTML (no caso do "Farmaindex") para obter informações desenvolvidas sobre cada medicamento.</li>
                    <li><strong>Organização dos Dados:</strong> Estrutura dos dados extraídos em um DataFrame do Pandas e concatena com os dados originais.</li>
                    <li><strong>Exportação:</strong> Salva o DataFrame resultante em um novo arquivo Excel para cada conjunto de códigos EAN processados.</li>
                </ul>
                <h2>Scripts Utilizados:</h2>
                <ul>
                    <li><strong>Web_Scraping_Site_principal.py:</strong> Focado na captura de dados do site "Consulta Remédios".</li>
                    <li><strong>Web_scraping_site_Secundario.py:</strong> Complementa a captura de dados para medicamentos cuja obtenção não foi obtida do site principal, buscando informações no site "Farmaindex".</li>
                </ul>

                <h2>Este projeto demonstra a utilização de:</h2>
                <ul>
                    <li>Web scraping e análise de dados com Python.</li>
                    <li>Manipulação e processamento de dados com Pandas.</li>
                    <li>Interação e integração de dados entre diferentes fontes e formatos.</li>
                </ul>
                <p>O código fornece uma solução automatizada e eficiente para a coleta e análise de informações de medicamentos, potencializando a capacidade de fornecimento de dados precisos e atualizados para diferentes aplicações na área da saúde e farmacêutica.</p>
            </div>
        
            <div id="web-development" class="project">
                <h1>Bula Fácil</h1>
                <p><strong><a href="https://jrstevani.github.io/Bula_facil_site/index.html" target="_blank">Veja o projeto</a></strong></p>
                
                <h2>Projeto Bula Fácil</h2>
                <p>O <strong>Projeto Bula Fácil</strong> oferece uma maneira prática e eficiente de acessar bulas de medicamentos. Com uma interface simples e intuitiva, os usuários podem buscar pelo nome do medicamento desejado e obter rapidamente o link para download da bula ou realizar o download direto do PDF.</p>
                
                <h3>Características Principais:</h3>
                <ul>
                    <li><strong>Interface Amigável:</strong> Fácil navegação e uso, permitindo que qualquer pessoa encontre rapidamente a bula do medicamento que precisa.</li>
                    <li><strong>Busca por Medicamento:</strong> O usuário insere o nome do medicamento e, em poucos cliques, obtém acesso à bula.</li>
                    <li><strong>Download Direto:</strong> Opção de baixar diretamente o PDF da bula, garantindo acesso rápido e sem complicações.</li>
                    <li><strong>Uso de API:</strong> Integração com uma API que realiza a solicitação e fornece o link para download ou o próprio arquivo PDF da bula.</li>
                </ul>
                
                <h3>Tecnologias Utilizadas:</h3>
                <ul>
                    <li><strong>HTML5:</strong> Utilizado para a estrutura da página.</li>
                    <li><strong>CSS:</strong> Usado para estilização e design responsivo.</li>
                    <li><strong>JavaScript:</strong> Implementado para interação e funcionalidade de busca e download.</li>
                    <li><strong>API:</strong> Empregada para solicitação e fornecimento das bulas de medicamentos.</li>
                </ul>
            </div>

        </section>
    </main>
</body>
</html>