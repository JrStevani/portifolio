<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projetos</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            background-color: #2c2c2c;
            color: #ffffff;
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }

        ::-webkit-scrollbar {
            display: none; 
        }


        header {
            background-color: #1c1c1c;
            padding: 15px;
            text-align: center;
        }

        header h1 {
            margin: 0;
            font-size: 2.5em;
        }

        .container {
            display: flex;
            flex: 1;
            flex-direction: row;
        }

        nav {
            background-color: #333333;
            padding: 20px;
            width: 250px;
            box-sizing: border-box;
            display: flex;
            flex-direction: column;
            align-items: center;
            height: 90vh;
        }

        nav img {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            margin-bottom: 20px;
            border: 3px solid #ffffff;
        }

        a {
            color: black;
            text-decoration: none;
            margin: 10px 0;
            font-size: 1.2em;
            text-align: center;
            width: 100%;
            padding: 10px;
            box-sizing: border-box;
            border-radius: 8px;
            border: 1px solid black;
        }

        a:hover {
            background-color: #f5f5f5;
        }

        section {
            display: block;
            padding: 20px;
            flex: 1;
            max-width: 100%;
            box-sizing: border-box;
        }

        .project {
            background-color: rgb(247, 247, 247);
            color: black;
            padding: 15px;
            margin-bottom: 20px;
            border-radius: 8px;
        }

        .project h2 {
            margin-top: 0;
            color: #181a20;
        }

        footer {
            background-color: #1c1c1c;
            padding: 1px;
            text-align: center;
            color: #777777;
        }

        @media (max-width: 768px) {
            .container {
                flex-direction: column;
            }

            nav {
                width: 100%;
                flex-direction: row;
                justify-content: space-around;
            }

            nav img {
                display: none;
            }

            nav a {
                margin: 5px;
                padding: 10px;
                font-size: 1em;
            }
        }
    </style>
    <script>
        function ajustarAlturaIframe() {
            const altura = document.body.scrollHeight;
            window.parent.postMessage(altura, '*'); 
        }

        window.addEventListener('load', ajustarAlturaIframe);
        window.addEventListener('resize', ajustarAlturaIframe);
    </script>
</head>
<body>
    <main>
        <section>
            <div id="web-scraping" class="project">
                <h2>Web Scraping em site de anime</h2>
                
        
                <a href="https://jrstevani.github.io/Web-Scraping-em-site-de-anime/index.html" target="_blank"><strong>Projeto detalhado</strong></a>
        
                <p><strong>Descrição do Projeto:</strong></p>
        
                <p><strong>Web Scraping de Animes:</strong> Captura de IDs de Episódios e Metadados</p>
        
                <p>O projeto "Web Scraping de Animes: Captura de IDs de Episódios e Metadados" utiliza a biblioteca Playwright para automatizar a extração de dados de um site de animes. O objetivo é capturar informações detalhadas sobre cada anime, como nome, descrição, gêneros, imagem, temporadas e episódios, e armazená-las em arquivos JSON. O projeto também cria diretórios específicos para organizar os dados, mantém registros de progresso e erros em arquivos de texto, e verifica se os animes já foram processados para evitar duplicações. Essa solução é eficiente e robusta para a extração e organização de grandes volumes de dados de animes.</p>
            </div>
        
            <div id="data-analysis" class="project">
                <h1>PMPF Simplify</h1>
                <p><a href="https://jrstevani.github.io/PMPF-Simplify/" target="_blank"><strong>Projeto detalhado</strong></a></p>
                
                <h2>Descrição do Projeto e Funcionalidades</h2>
                <p>Este projeto tem como objetivo principal a padronização e análise de dados de produtos presentes em notas fiscais eletrônicas (NFes). Ele é dividido em duas etapas principais: a padronização de dados e a identificação de erros, seguida pela análise estatística e cálculo de variações. As funcionalidades do projeto incluem:</p>
                <ul>
                    <li><strong>Carregamento e validação de dados</strong>: Leitura de arquivos Excel contendo dados de produtos e tabela de erros.</li>
                    <li><strong>Padronização de dados</strong>: Aplicação de intervalos de aceitação para valores unitários e filtragem de valores discrepantes.</li>
                    <li><strong>Análise estatística</strong>: Cálculo de variâncias, desvios padrão e outras métricas estatísticas para cada grupo de produtos.</li>
                    <li><strong>Geração de relatórios</strong>: Criação de relatórios detalhados com análise de erros, variações de preços e distribuição de vendas por setor.</li>
                    <li><strong>Salvamento de resultados</strong>: Armazenamento dos dados padronizados e analisados em arquivos Excel para posterior revisão e utilização.</li>
                </ul>
                
                <h2>Detalhamento das Etapas</h2>
                
                <h3>Primeira Etapa: Padronização de Dados e Identificação de Erros</h3>
                <ul>
                    <li><strong>Carregamento de Dados</strong>: Carregamento de arquivos Excel contendo dados padronizados e tabela de erros. Verificação e carregamento de arquivo de configuração <code>Gtin.xlsx</code>.</li>
                    <li><strong>Inicialização de Estruturas</strong>: Criação de DataFrames para armazenar resultados, dados de desvio padrão, fornecedores e resultados finais. Inicialização de dicionários para armazenar variações e intervalos de aceitação.</li>
                    <li><strong>Cálculo de Intervalos de Aceitação</strong>: Cálculo de limites inferior e superior de aceitação para valores unitários de produtos agrupados por código GTIN.</li>
                    <li><strong>Filtragem de Dados</strong>: Filtragem de dados com base nos intervalos de aceitação. Valores dentro dos intervalos são considerados corretos, enquanto valores fora são classificados como erros.</li>
                    <li><strong>Análise Estatística</strong>: Cálculo de variâncias e desvios padrão para cada grupo de produtos. Cálculo do valor total das notas fiscais para posterior análise percentual.</li>
                    <li><strong>Compilação dos Resultados</strong>: Cálculo de várias métricas para cada produto e armazenamento em tabelas de resultados e fornecedores.</li>
                    <li><strong>Salvamento dos Resultados</strong>: Salvamento de DataFrames resultantes em um arquivo Excel, organizados em várias abas, incluindo dados padronizados, tabela de erros, dados tratados, relatório e análise de erros por fornecedores.</li>
                </ul>
                
                <h3>Segunda Etapa: Análise Estatística e Cálculo de Variações</h3>
                <ul>
                    <li><strong>Preparação dos Dados</strong>: Carregamento dos dados previamente padronizados e filtrados. Inicialização de estruturas de dados para armazenar resultados da análise estatística.</li>
                    <li><strong>Cálculo de Variações</strong>: Agrupamento de dados por código GTIN e cálculo de soma de unidades comerciais e valor total do produto. Cálculo de variâncias e desvios padrão para cada grupo de produtos.</li>
                    <li><strong>Análise de Desvios Padrão</strong>: Identificação de produtos com variações fora dos intervalos de aceitação. Remoção de valores discrepantes e recalculação de métricas.</li>
                    <li><strong>Compilação de Relatórios</strong>: Criação de relatórios detalhados contendo análise de quantidade de erros, variações de preços e distribuições de vendas por setor. Preenchimento de tabelas com dados consolidados e estatísticas calculadas.</li>
                    <li><strong>Salvamento Final dos Resultados</strong>: Salvamento de todos os resultados e análises em um arquivo Excel, organizados em abas específicas para fácil acesso e revisão.</li>
                </ul>
                
                <h2>Tecnologias Utilizadas</h2>
                <ul>
                    <li><strong>Python</strong>: Linguagem principal de programação utilizada para todo o desenvolvimento do projeto.</li>
                    <li><strong>Pandas</strong>: Biblioteca essencial para manipulação e análise de dados, usada para operações com DataFrames.</li>
                    <li><strong>Openpyxl</strong>: Biblioteca usada para leitura e escrita de arquivos Excel.</li>
                    <li><strong>NumPy</strong>: Biblioteca usada para cálculos numéricos e operações matemáticas.</li>
                    <li><strong>PyQt5</strong>: Biblioteca usada para criar a interface gráfica do usuário (GUI) que facilita a interação com o sistema.</li>
                    <li><strong>Os</strong>: Módulo usado para operações relacionadas ao sistema operacional, como verificação da existência de arquivos.</li>
                    <li><strong>Bibliotecas de estatística</strong>: Ferramentas para cálculos estatísticos como variância e desvio padrão.</li>
                </ul>
            </div>

            <div id="web-scraping-medicamentos" class="project">
                <h1>Web Scraping para Medicamentos</h1>
                <p><a href="https://jrstevani.github.io/Web_Scraping_Para_Medicamentos/" target="_blank"><strong>Projeto detalhado</strong></a></p>
                <p>Este projeto visa capturar e analisar dados de medicamentos a partir dos sites "Consulta Remédios" e "Farmaindex" utilizando Python. Através de uma combinação de web scraping com as bibliotecas BeautifulSoup e requisições HTTP com a biblioteca requests, os scripts buscam informações planejadas sobre medicamentos com base em seus códigos EAN presentes em um arquivo Excel.</p>

                <h2>Funcionalidades do Projeto:</h2>
                <ul>
                    <li><strong>Leitura de Dados:</strong> Os scripts lêem os códigos EAN de medicamentos de uma planilha em um arquivo Excel.</li>
                    <li><strong>Web Scraping:</strong> Utiliza a biblioteca BeautifulSoup para extrair dados específicos dos sites "Consulta Remédios" e "Farmaindex", como apresentação, nome do medicamento, princípio ativo e fabricante.</li>
                    <li><strong>Tratamento de Dados:</strong> Os dados extraídos são organizados em um DataFrame do Pandas para fácil manipulação e análise.</li>
                    <li><strong>Exportação de Dados:</strong> Os resultados são salvos em novas planilhas Excel, permitindo uma análise estruturada e comparativa dos dados.</li>
                </ul>

                <h2>Etapas do Processo:</h2>
                <ul>
                    <li><strong>Requisição HTTP:</strong> Realiza uma solicitação GET para a URL do medicamento com base no código EAN.</li>
                    <li><strong>Análise HTML:</strong> Utiliza BeautifulSoup para analisar o conteúdo HTML e encontrar as divs específicas que contêm os dados necessários.</li>
                    <li><strong>Extração de Dados:</strong> Decodifica o JSON contido nos atributos HTML (no caso do "Consulta Remédios") ou extrai diretamente os textos das tags HTML (no caso do "Farmaindex") para obter informações detalhadas sobre cada medicamento.</li>
                    <li><strong>Organização dos Dados:</strong> Estrutura os dados extraídos em um DataFrame do Pandas e concatena com os dados originais.</li>
                    <li><strong>Exportação:</strong> Salva o DataFrame resultante em um novo arquivo Excel para cada conjunto de códigos EAN processados.</li>
                </ul>

                <h2>Scripts Utilizados:</h2>
                <ul>
                    <li><strong>Web_Scraping_Site_principal.py:</strong> Focado na captura de dados do site "Consulta Remédios".</li>
                    <li><strong>Web_scraping_site_Secundario.py:</strong> Complementa a captura de dados para medicamentos cujas informações não foram obtidas do site principal, buscando dados no site "Farmaindex".</li>
                </ul>

                <p>Este projeto demonstra a utilização de:</p>
                <ul>
                    <li>Web scraping e análise de dados com Python.</li>
                    <li>Manipulação e processamento de dados com Pandas.</li>
                    <li>Interação e integração de dados entre diferentes fontes e formatos.</li>
                </ul>

                <p>O código fornece uma solução automatizada e eficiente para a coleta e análise de informações de medicamentos, potencializando a capacidade de fornecimento de dados precisos e atualizados para diferentes aplicações na área da saúde e farmacêutica.</p>
            
            </div>
        
            <div id="web-development" class="project">
                <h1>Bula Fácil Web</h1>
                <p><strong><a href="https://jrstevani.github.io/Bula_facil_site/index.html" target="_blank">Veja o projeto</a></strong></p>
                
                <p>O Projeto Bula Fácil oferece uma maneira prática e eficiente de acessar bulas de medicamentos. Com uma interface simples e intuitiva, os usuários podem buscar pelo nome do medicamento desejado e obter rapidamente o link para download da bula ou realizar o download direto do PDF.</p>

                <h2>Características Principais:</h2>
                <ul>
                    <li><strong>Interface Amigável:</strong> Fácil navegação e uso, permitindo que qualquer pessoa encontre rapidamente a bula do medicamento que precisa.</li>
                    <li><strong>Busca por Medicamento:</strong> O usuário insere o nome do medicamento e, em poucos cliques, obtém acesso à bula.</li>
                    <li><strong>Download Direto:</strong> Opção de baixar diretamente o PDF da bula, garantindo acesso rápido e sem complicações.</li>
                    <li><strong>Uso de API:</strong> Integração com uma API que realiza a solicitação e fornece o link para download ou o próprio arquivo PDF da bula.</li>
                </ul>

                <h2>Tecnologias Utilizadas:</h2>
                <ul>
                    <li><strong>HTML5:</strong> Utilizado para a estrutura da página.</li>
                    <li><strong>CSS:</strong> Usado para estilização e design responsivo.</li>
                    <li><strong>JavaScript:</strong> Implementado para interação e funcionalidade de busca e download.</li>
                    <li><strong>API:</strong> Empregada para solicitação e fornecimento das bulas de medicamentos.</li>
                </ul>
            </div>

            <div id="bula-facil" class="project">
                <h1>Bula Fácil Python</h1>
                
        
                <p><a href="https://github.com/JrStevani/Bula_facil" target="_blank"><strong>Projeto detalhado</strong></a></p>
        
                <h2><strong>Descrição do Projeto:</strong></h2>
        
                <p>O projeto "Sistema de Download de Bulas de Medicamentos" automatiza o processo de download de bulas em formato PDF usando um script em Python. O usuário fornece o nome de um medicamento, e o script consulta uma API pública para obter o ID exclusivo da bula correspondente. Com esse ID, o script baixa o arquivo PDF da bula e o salva localmente. O projeto inclui tratamento de erros para lidar com problemas comuns, como falhas de conexão e respostas inválidas. O objetivo é facilitar o acesso e armazenamento de bulas para referência futura, utilizando tecnologias como Python, Requests e JSON.</p>
            </div>

            <div id="banco-de-dados" class="project">
                <h1>Automação com banco de dados</h1>
                <p><a href="https://jrstevani.github.io/Insercao_automatica_DB/" target="_blank"><strong>Projeto detalhado</strong></a></p>
                <h2>Descrição do Projeto</h2>
                <p>Este projeto em Python tem como objetivo conectar-se a um banco de dados MySQL para armazenar informações detalhadas sobre animes. As principais funcionalidades e etapas do código incluem:</p>

                <h2>Funcionalidades Principais:</h2>
                <ul>
                    <li><strong>Conexão ao Banco de Dados:</strong> O código estabelece uma conexão com o banco de dados MySQL chamado <code>db_animes</code>.</li>
                    <li><strong>Criação da Tabela <code>animes</code>:</strong> Se a tabela <code>animes</code> não existir, o código cria a tabela com as seguintes colunas:
                        <ul>
                            <li><strong>id:</strong> Um identificador único incremental automático.</li>
                            <li><strong>nome:</strong> Nome do anime.</li>
                            <li><strong>descrição:</strong> Descrição do anime.</li>
                            <li><strong>linguagem:</strong> Linguagem do anime (dublado ou legendado).</li>
                            <li><strong>generos:</strong> Gêneros do anime, armazenados como JSON.</li>
                            <li><strong>imagem:</strong> Caminho da imagem do anime.</li>
                            <li><strong>temporada_episodios:</strong> Informações das temporadas e episódios, armazenados como JSON.</li>
                        </ul>
                    </li>
                    <li><strong>Leitura e Inserção de Dados:</strong> O código percorre dois diretórios (<code>dublado</code> e <code>legendado</code>) para ler arquivos JSON contendo informações dos animes. Para cada anime, os dados são extraídos e inseridos na tabela <code>animes</code> no banco de dados.</li>
                    <li><strong>Confirmação e Fechamento:</strong> Após a inserção dos dados, a transação é fechada (commit) e a conexão com o banco de dados é encerrada. No final, é exibido o total de animes inseridos.</li>
                </ul>

                <h2>Detalhes Técnicos</h2>

                <h3>Bibliotecas Utilizadas:</h3>
                <ul>
                    <li><strong>mysql.connector:</strong> Para conexão com o banco de dados MySQL.</li>
                    <li><strong>json:</strong> Para manipulação de dados JSON.</li>
                    <li><strong>os:</strong> Para manipulação de diretórios e arquivos.</li>
                </ul>

                <h3>Estrutura de Diretórios e Arquivos:</h3>
                <ul>
                    <li>Diretórios <code>.\Resultado\dublado\Animes</code> e <code>.\Resultado\legendado\Animes</code> contêm subdiretórios para cada anime.</li>
                    <li>Cada subdiretório contém um arquivo JSON chamado <code>&lt;nome_do_anime&gt;-episodios.json</code> com as informações do anime.</li>
                </ul>
            </div>

        </section>
    </main>
</body>
</html>
